{"cells":[{"cell_type":"markdown","metadata":{"id":"9dBC0DJLIEKX"},"source":["<h1>loading train, validation and test data<h1>"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13684,"status":"ok","timestamp":1697643867170,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"F3xXUMDVfRI7","outputId":"7dc58eb7-dc16-448c-87d5-062592b52c61"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install --quiet transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5780,"status":"ok","timestamp":1697643872946,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"KJs3tsZEdtJP"},"outputs":[],"source":["import time\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from tqdm.notebook import tqdm\n","from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AutoModelForMaskedLM, AutoTokenizer"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697643872947,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"7Q8iG3vluRLA"},"outputs":[],"source":["###Hyperparameter for the new model\n","#defining some hyperparameters\n","max_number_input_tokens=512\n","batch_size_training = 8\n","first_dropout_rate = 0.0\n","hidden_output = 768\n","bert_model_name = \"bert-base-multilingual-uncased\"\n","adam_opt_lr = 8e-6\n","scheduler_step = 1\n","scheduler_gamma = 0.98\n","epochs = 8\n","classes = 2\n","model_layer = ''\n","name_change=''\n","headlineContentSeparator = ' \\\\\\\\ '\n","\n","#other options\n","isSaveModel = False"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35387,"status":"ok","timestamp":1697643908328,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"rXg4692CZ5cb","outputId":"355eb00c-603f-4cce-969d-71ee03b48319"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","DirPath = ('/content/drive/My Drive/FakeNews/')\n","TestPath = DirPath+'test.csv'\n","ValPath = DirPath+'val.csv'\n","TrainPath = DirPath+'train.csv'\n","ModelPath = DirPath+'Models/'+'FNBaseline_mbert.pth'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1697643908329,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"AEBojsPoiA_b"},"outputs":[],"source":["def interchange(df_train,pos,label):\n","  #setting the first sample to be with label '0'\n","  zero_index = df_train[df_train['label'] == label].index[0]\n","  first_index=pos\n","  # interchange the samples\n","  df_train.iloc[[first_index, zero_index]] = df_train.iloc[[zero_index, first_index]]\n","  return df_train"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1697643908329,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"EmUATD-1YehW"},"outputs":[],"source":["def balanceclasses(df_train):\n","  class_counts = df_train['label'].value_counts()\n","  min_count = class_counts.max()\n","\n","  # Create new DataFrames for each class with fewer samples\n","  new_dfs = []\n","  for label, count in class_counts.items():\n","    if count == min_count:\n","        continue\n","    df_label = df_train[df_train['label'] == label]\n","    num_copies = min_count // count\n","    new_df_label = pd.concat([df_label] * num_copies, ignore_index=True)\n","    new_df_label = new_df_label.head(min_count-count)\n","    #print(new_df_label.head(10))\n","    new_dfs.append(new_df_label)\n","\n","  # Concatenate the new DataFrames with the original DataFrame\n","  df_balanced = pd.concat([df_train] + new_dfs, ignore_index=True).sample(frac=1).reset_index(drop=True)\n","  return df_balanced"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10874,"status":"ok","timestamp":1697643919190,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"Z-k2B2ThB8SY","outputId":"5ff1223c-7d85-4639-a725-f22c6a0dcdb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["(43106, 3)\n","(9237, 3)\n","(9238, 3)\n","                                                Headline  \\\n","0             ঢাকায় বাসের ধাক্কায় কৃষি কর্মকর্তার মৃত্যু   \n","1                   জাপানে ঘূর্ণিঝড় ট্রামির আঘাতে নিহত ২   \n","2      প্রতিরক্ষা মন্ত্রণালয়ে বিশাল নিয়োগ বিজ্ঞপ্তি ২০১৮   \n","3            তত্ত্বাবধায়ক সরকার গঠনের নির্দেশনা চেয়ে রিট   \n","4      জগাখিচুড়ি ঐক্যের কোনও ভবিষ্যৎ নেই: ওবায়দুল কাদের   \n","...                                                  ...   \n","43101  মধ্য প্রদেশে আশ্রয় কেন্দ্রে প্রতিবন্ধী নারীকে ...   \n","43102    ঢাকা ভাগের প্রতিবাদে মহা-সমাবেশ | দৈনিক মতিকণ্ঠ   \n","43103  ChotoBhai' এর ভিডিও রিপোর্ট করে takeout 2.0 থে...   \n","43104  'আমি কিছুই জানি না, ও তো সৎ ছিল,' মিঠুন প্রসঙ্...   \n","43105             হাসানুল হক ইনুর বিরুদ্ধ মানহানির মামলা   \n","\n","                                                 Content  Label  \n","0      নিজস্ব প্রতিবেদক : রাজধানীর ফার্মগেটে বাসের ধা...      1  \n","1      জাপানে শক্তিশালী ঘূর্ণিঝড়ের আঘাতে দুজনের প্রাণ...      1  \n","2      প্রতিরক্ষা মন্ত্রণালয়ের নিয়ন্ত্রণাধীন প্রধান প...      1  \n","3      জাতীয় সংসদ নির্বাচনের ৪২ দিন আগে সংসদ ভেঙে দিয়...      1  \n","4      বিএনপি ও জাতীয় ঐক্য প্রক্রিয়ার ‘নির্বাচনকালীন ...      1  \n","...                                                  ...    ...  \n","43101  ধর্ষণের কারণে দৃষ্টি ও বাক প্রতিবন্ধী ওই নারী ...      0  \n","43102  নিজস্ব মতিবেদক | তারিখ: ২৯-১১-২০১১ঢাকা সিটি কর...      0  \n","43103  রাফসান দ্য ছোটভাইয়ের takeout 2.0 নিয়ে নেগেটিভ ...      0  \n","43104  সোনারপুরের ভ্যাকসিনকাণ্ডকে ঘিরে ইতিমধ্যেই শোরগ...      0  \n","43105  আদালত মতিবেদক প্রয়াত রাষ্ট্রপতি জিয়াউর রহমান...      0  \n","\n","[43106 rows x 3 columns]\n","              Label\n","count  43106.000000\n","mean       0.790470\n","std        0.406978\n","min        0.000000\n","25%        1.000000\n","50%        1.000000\n","75%        1.000000\n","max        1.000000\n","1    34074\n","0     9032\n","Name: Label, dtype: int64\n","1    7302\n","0    1935\n","Name: Label, dtype: int64\n","1    7302\n","0    1936\n","Name: Label, dtype: int64\n"]}],"source":["#df loading\n","df_train = pd.read_csv(TrainPath) # [['sentence','hate speech']]\n","df_val = pd.read_csv(ValPath)#[['sentence','hate speech']]\n","df_test = pd.read_csv(TestPath)#[['sentence','hate speech']]\n","\n","#concatenating all the data\n","# df_train = pd.concat([df_train, df_val, df_test], ignore_index=True)\n","\n","print(df_train.shape)\n","print(df_val.shape)\n","print(df_test.shape)\n","print(df_train)\n","print(df_train.describe())\n","print(df_train['Label'].value_counts())\n","print(df_val['Label'].value_counts())\n","print(df_test['Label'].value_counts())"]},{"cell_type":"markdown","metadata":{"id":"nhygxywpTztv"},"source":["<h1>preparing training, validation and test data. Preparing model. Training model<h1>"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":977,"status":"ok","timestamp":1697643920165,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"MtIzKtM_xqHt"},"outputs":[],"source":["class NewsDatasets(Dataset):\n","    def __init__(self, data, max_length=max_number_input_tokens):\n","        self.data = data\n","\n","        self.config = {\n","            \"max_length\": max_length,\n","            \"padding\": \"max_length\",\n","            \"return_tensors\": \"pt\",\n","            \"truncation\": True,\n","            \"add_special_tokens\": True,\n","            \"truncation_strategy\":\"longest_first\"\n","        }\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        value = self.data.iloc[idx]\n","        # print(value[\"Headline\"],value['Content']) #debugging dataloader\n","        return value['Headline']+headlineContentSeparator+value['Content'] , value['Label']"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1697643920166,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"aK9mkfgDxrVZ"},"outputs":[],"source":["training_data = NewsDatasets(df_train)\n","train_dataloader = DataLoader(training_data, batch_size=batch_size_training, shuffle=True)\n","\n","val_data = NewsDatasets(df_val)\n","val_dataloader = DataLoader(val_data, batch_size=batch_size_training, shuffle=False)\n","\n","test_data = NewsDatasets(df_test)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size_training, shuffle=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"PSjqu8UTubQA","executionInfo":{"status":"ok","timestamp":1697643920166,"user_tz":-360,"elapsed":8,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"}}},"outputs":[],"source":["# #model for finetuning collected data\n","# class BERTBengaliLastTwoPooler(nn.Module):\n","#     def __init__(self, bert):\n","#         super(BERTBengaliLastTwoPooler, self).__init__()\n","#         self.bert = bert\n","#         self.drop_out = nn.Dropout(first_dropout_rate)\n","#         self.l0 =  nn.Linear(hidden_output * 3, classes)\n","#         #torch.nn.init.normal_(self.l0.weight, std=0.02)\n","#         self.softmax = nn.Softmax(dim=1)\n","\n","#     def forward(self, input_ids, attention_mask, token_type_ids):\n","#         outputs = self.bert(\n","#             input_ids,\n","#             attention_mask=attention_mask,\n","#             token_type_ids=token_type_ids\n","#         )\n","#         mpool, _ = torch.max(outputs.hidden_states[-1], 1)\n","#         out = torch.cat((mpool, outputs.hidden_states[-2][:,0,:],outputs.pooler_output), dim=-1)\n","#         out = self.drop_out(out)\n","#         #out = out[:,0,:]\n","#         logits = self.l0(out)\n","#         logits = self.softmax(logits)\n","#         return logits"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"4_sM1dZ_Etmu","executionInfo":{"status":"ok","timestamp":1697643920166,"user_tz":-360,"elapsed":7,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"}}},"outputs":[],"source":["# class CustomBERTBengali(nn.Module):\n","#     def __init__(self, bert):\n","#         super(CustomBERTBengali, self).__init__()\n","#         self.bert = bert\n","#         self.bert_drop = nn.Dropout(first_dropout_rate)\n","#         self.tanh = nn.Tanh()\n","#         self.out = nn.Linear(hidden_output * 3, classes)\n","#         self.softmax = nn.Softmax(dim=1)\n","\n","#     def forward(self, input_ids, attention_mask, token_type_ids):\n","#         outputs = self.bert(\n","#             input_ids,\n","#             attention_mask=attention_mask,\n","#             token_type_ids=token_type_ids\n","#         )\n","#         o1 = outputs.hidden_states[-1]\n","#         o2 = outputs.pooler_output\n","#         apool = torch.mean(o1, 1)\n","#         mpool, _ = torch.max(o1, 1)\n","#         pooled_output = o2\n","#         cat = torch.cat((apool, mpool, pooled_output), 1)\n","#         bo = self.bert_drop(cat)\n","#         logits = self.out(bo)\n","#         #logits = self.softmax(logits)\n","#         return logits"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697643920166,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"BAH0JhR_gVdV"},"outputs":[],"source":["class BERTBengaliLastTwoPooler(nn.Module):\n","    def __init__(self, bert):\n","        super(BERTBengaliLastTwoPooler, self).__init__()\n","        self.bert = bert\n","        self.drop_out = nn.Dropout(first_dropout_rate)\n","        self.l0 =  nn.Linear(hidden_output * 3, classes)\n","        #torch.nn.init.normal_(self.l0.weight, std=0.02)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids\n","        )\n","        mpool, _ = torch.max(outputs.hidden_states[-1], 1)\n","        out = torch.cat((mpool, outputs.hidden_states[-2][:,0,:],outputs.pooler_output), dim=-1)\n","        out = self.drop_out(out)\n","        #out = out[:,0,:]\n","        logits = self.l0(out)\n","        # logits = self.softmax(logits)\n","        return logits"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697643920167,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"Cf54Z8g_qqzb"},"outputs":[],"source":["class CustomBERTBengali(nn.Module):\n","    def __init__(self, bert):\n","        super(CustomBERTBengali, self).__init__()\n","        self.bert = bert\n","        self.bert_drop = nn.Dropout(first_dropout_rate)\n","        self.tanh = nn.Tanh()\n","        self.out = nn.Linear(hidden_output * 2, 2)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids=None):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            # token_type_ids=token_type_ids\n","        )\n","        # print(dict(outputs).keys())\n","        o1 = outputs.hidden_states[-1]\n","        # o2 = outputs.pooler_output\n","        apool = torch.mean(o1, 1)\n","        mpool, _ = torch.max(o1, 1)\n","        # pooled_output = o2\n","        cat = torch.cat((apool, mpool), 1)\n","        bo = self.bert_drop(cat)\n","        logits = self.out(bo)\n","        logits = self.softmax(logits)\n","        return logits"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697643920167,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"W2Yk-_A3Y6OH"},"outputs":[],"source":["#model for finetuning collected data\n","class BERTBengaliLastTwoPoolerFreeze(nn.Module):\n","    def __init__(self, bert):\n","        super(BERTBengaliLastTwoPoolerFreeze, self).__init__()\n","        self.bert = bert\n","        self.drop_out = nn.Dropout(first_dropout_rate)\n","        self.l2 = nn.Linear(hidden_output * 3, hidden_output * 2)\n","        self.activation = nn.Tanh()\n","        self.l1 = nn.Linear(hidden_output * 2, hidden_output * 2)\n","        self.activation = nn.Tanh()\n","        self.l0 = nn.Linear(hidden_output * 2, classes)\n","        #torch.nn.init.normal_(self.l0.weight, std=0.02)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids\n","        )\n","        mpool, _ = torch.max(outputs.hidden_states[-1], 1)\n","        out = torch.cat((outputs.hidden_states[-2][:,0,:], mpool), dim=-1)#,outputs.pooler_output\n","        out = self.drop_out(out)\n","        out = self.l2(out)\n","        out = self.activation(out)\n","        out = self.l1(out)\n","        out = self.activation(out)\n","        logits = self.l0(out)\n","        #prob = self.softmax(logits)\n","        return logits\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697643920167,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"i4yc19NbQkJh"},"outputs":[],"source":["#model for finetuning collected data\n","class BERTBengaliLastTwoPoolerFreezePrev(nn.Module):\n","    def __init__(self, bert):\n","        super(BERTBengaliLastTwoPoolerFreezePrev, self).__init__()\n","        self.bert = bert\n","        self.drop_out = nn.Dropout(first_dropout_rate)\n","        self.l1 = nn.Linear(hidden_output * 2, hidden_output * 2)\n","        self.activation = nn.Tanh()\n","        self.l0 = nn.Linear(hidden_output * 2, classes)\n","        #torch.nn.init.normal_(self.l0.weight, std=0.02)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids\n","        )\n","        mpool, _ = torch.max(outputs.hidden_states[-1], 1)\n","        out = torch.cat((outputs.hidden_states[-2][:,0,:], mpool,outputs.pooler_output), dim=-1)\n","        out = self.drop_out(out)\n","        out = self.l1(out)\n","        out = self.activation(out)\n","        logits = self.l0(out)\n","        #prob = self.softmax(logits)\n","        return logits\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7aacc5450aaf43d59469f2b45fa80fe5","0d230aa88603405582e4637c97cf68b3","a7a2300ad1a847a6a52e8c2c87a3e708","d01a5d3d7c024e3e9230808cddcddca4","3e5637ebf22a4597ad5491f089b0e7c4","4164cafdc0d847b7aa83967087892987","9b0ccec5b9c542878a610a38ebdf3c3a","03b38a5916324b61b9db9935047a0593","57befa01df3a4d2f95ab030ed3b7fca8","a0fe7504b9ed4e6fa19237e4e96b7191","d593a8fe63214b9692fef55e91a6f50c","c75a7f464d3c46be9d179437e18532f8","f6dc29757dde4b92aafe09dac81c3595","b5c2ae66786c47da8f99fd6f4500ae7c","f2618c5944004f61bb7c5326e349a4a4","3d7c646616594143a7873e366cd05774","67aad554bb284250b042774279e08b53","db2aaf67a8a94fcf8ccecac12026ab09","62a1ca95ea6a4966ae40e5e74ef8b1ab","c2342b7fb7eb421584f43cad5c8821a9","bd6bea4b34c94cc194d2de4c351310fb","ba24111f6d314235910d34123aba8857","43eff258fb444bcda2962855d995fbf4","bb2e571f31a445b99296fe3f2c710bde","736c264482694094b62aef3ac4841b44","52ddd3d40a474a51b8b3fd97b279462b","f92d08e2a9164f32af1d4fd43610c623","911a995098bf4f68bdd6d6ca15c1b1c6","569bb0d01e254aca914868043822c30c","b9519362ff4b489d95e0429a84090d24","b12eae5c6b6241b1a3008a21d7f2dc5d","ae7e725858ad46ff98cd5406c7d0161b","5354b17935ce43b8a8876d2b3504a69e","8230656aabcf4245a77bc5b4775841dc","a61a834f7f5b4f9b9c2432bdae231860","c3855fc4a51646acb462be38579419cf","2b513541b41342108ae03a3c627388f0","13642299507543bb89bb5e2078c366b0","f42002b010a24db784789cd2bc62cfa7","64b7810ac2224898a78c50cf04c76d36","b81a2606ac3e47b0ae879f4480da601f","62e203044d2c4460a2cd93c0cae8d704","319c6a40daa74a98bd33030cb199792d","5bc8b324489d41b3b3bb93179c2e17ef","db267d2070804805b2f090ded73f7198","f4fce8ab737a4f2ca13a68852c76a438","ef412e451d524ebd85df4ec63668a57d","2f07b0fae0614619815e089fe375621d","30f300aa16ed441984aa81a478234e02","33fb3d91c292412781a4aaaa4bfa063b","eef00cd64eb14d9c898b6167619f79dd","eedb1062cc9e4b418c6e4330154a8870","a1b74280444d4ac88159b3a703292d20","da2c68f1b27b40fba070b246f42083e3","ebeb6a3138ca476f9974e66a3d0fd534"]},"executionInfo":{"elapsed":13710,"status":"ok","timestamp":1697644028694,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"9z9eXknsUPpV","outputId":"33354485-3a39-4c02-f087-d5eb30521ae7"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aacc5450aaf43d59469f2b45fa80fe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/672M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c75a7f464d3c46be9d179437e18532f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43eff258fb444bcda2962855d995fbf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8230656aabcf4245a77bc5b4775841dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db267d2070804805b2f090ded73f7198"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["name: bert.embeddings.word_embeddings.weight is trainable\n","name: bert.embeddings.position_embeddings.weight is trainable\n","name: bert.embeddings.token_type_embeddings.weight is trainable\n","name: bert.embeddings.LayerNorm.weight is trainable\n","name: bert.embeddings.LayerNorm.bias is trainable\n","name: bert.encoder.layer.0.attention.self.query.weight is trainable\n","name: bert.encoder.layer.0.attention.self.query.bias is trainable\n","name: bert.encoder.layer.0.attention.self.key.weight is trainable\n","name: bert.encoder.layer.0.attention.self.key.bias is trainable\n","name: bert.encoder.layer.0.attention.self.value.weight is trainable\n","name: bert.encoder.layer.0.attention.self.value.bias is trainable\n","name: bert.encoder.layer.0.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.0.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.0.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.0.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.0.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.0.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.0.output.dense.weight is trainable\n","name: bert.encoder.layer.0.output.dense.bias is trainable\n","name: bert.encoder.layer.0.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.0.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.1.attention.self.query.weight is trainable\n","name: bert.encoder.layer.1.attention.self.query.bias is trainable\n","name: bert.encoder.layer.1.attention.self.key.weight is trainable\n","name: bert.encoder.layer.1.attention.self.key.bias is trainable\n","name: bert.encoder.layer.1.attention.self.value.weight is trainable\n","name: bert.encoder.layer.1.attention.self.value.bias is trainable\n","name: bert.encoder.layer.1.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.1.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.1.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.1.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.1.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.1.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.1.output.dense.weight is trainable\n","name: bert.encoder.layer.1.output.dense.bias is trainable\n","name: bert.encoder.layer.1.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.1.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.2.attention.self.query.weight is trainable\n","name: bert.encoder.layer.2.attention.self.query.bias is trainable\n","name: bert.encoder.layer.2.attention.self.key.weight is trainable\n","name: bert.encoder.layer.2.attention.self.key.bias is trainable\n","name: bert.encoder.layer.2.attention.self.value.weight is trainable\n","name: bert.encoder.layer.2.attention.self.value.bias is trainable\n","name: bert.encoder.layer.2.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.2.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.2.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.2.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.2.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.2.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.2.output.dense.weight is trainable\n","name: bert.encoder.layer.2.output.dense.bias is trainable\n","name: bert.encoder.layer.2.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.2.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.3.attention.self.query.weight is trainable\n","name: bert.encoder.layer.3.attention.self.query.bias is trainable\n","name: bert.encoder.layer.3.attention.self.key.weight is trainable\n","name: bert.encoder.layer.3.attention.self.key.bias is trainable\n","name: bert.encoder.layer.3.attention.self.value.weight is trainable\n","name: bert.encoder.layer.3.attention.self.value.bias is trainable\n","name: bert.encoder.layer.3.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.3.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.3.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.3.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.3.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.3.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.3.output.dense.weight is trainable\n","name: bert.encoder.layer.3.output.dense.bias is trainable\n","name: bert.encoder.layer.3.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.3.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.4.attention.self.query.weight is trainable\n","name: bert.encoder.layer.4.attention.self.query.bias is trainable\n","name: bert.encoder.layer.4.attention.self.key.weight is trainable\n","name: bert.encoder.layer.4.attention.self.key.bias is trainable\n","name: bert.encoder.layer.4.attention.self.value.weight is trainable\n","name: bert.encoder.layer.4.attention.self.value.bias is trainable\n","name: bert.encoder.layer.4.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.4.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.4.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.4.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.4.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.4.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.4.output.dense.weight is trainable\n","name: bert.encoder.layer.4.output.dense.bias is trainable\n","name: bert.encoder.layer.4.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.4.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.5.attention.self.query.weight is trainable\n","name: bert.encoder.layer.5.attention.self.query.bias is trainable\n","name: bert.encoder.layer.5.attention.self.key.weight is trainable\n","name: bert.encoder.layer.5.attention.self.key.bias is trainable\n","name: bert.encoder.layer.5.attention.self.value.weight is trainable\n","name: bert.encoder.layer.5.attention.self.value.bias is trainable\n","name: bert.encoder.layer.5.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.5.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.5.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.5.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.5.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.5.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.5.output.dense.weight is trainable\n","name: bert.encoder.layer.5.output.dense.bias is trainable\n","name: bert.encoder.layer.5.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.5.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.6.attention.self.query.weight is trainable\n","name: bert.encoder.layer.6.attention.self.query.bias is trainable\n","name: bert.encoder.layer.6.attention.self.key.weight is trainable\n","name: bert.encoder.layer.6.attention.self.key.bias is trainable\n","name: bert.encoder.layer.6.attention.self.value.weight is trainable\n","name: bert.encoder.layer.6.attention.self.value.bias is trainable\n","name: bert.encoder.layer.6.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.6.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.6.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.6.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.6.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.6.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.6.output.dense.weight is trainable\n","name: bert.encoder.layer.6.output.dense.bias is trainable\n","name: bert.encoder.layer.6.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.6.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.7.attention.self.query.weight is trainable\n","name: bert.encoder.layer.7.attention.self.query.bias is trainable\n","name: bert.encoder.layer.7.attention.self.key.weight is trainable\n","name: bert.encoder.layer.7.attention.self.key.bias is trainable\n","name: bert.encoder.layer.7.attention.self.value.weight is trainable\n","name: bert.encoder.layer.7.attention.self.value.bias is trainable\n","name: bert.encoder.layer.7.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.7.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.7.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.7.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.7.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.7.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.7.output.dense.weight is trainable\n","name: bert.encoder.layer.7.output.dense.bias is trainable\n","name: bert.encoder.layer.7.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.7.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.8.attention.self.query.weight is trainable\n","name: bert.encoder.layer.8.attention.self.query.bias is trainable\n","name: bert.encoder.layer.8.attention.self.key.weight is trainable\n","name: bert.encoder.layer.8.attention.self.key.bias is trainable\n","name: bert.encoder.layer.8.attention.self.value.weight is trainable\n","name: bert.encoder.layer.8.attention.self.value.bias is trainable\n","name: bert.encoder.layer.8.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.8.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.8.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.8.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.8.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.8.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.8.output.dense.weight is trainable\n","name: bert.encoder.layer.8.output.dense.bias is trainable\n","name: bert.encoder.layer.8.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.8.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.9.attention.self.query.weight is trainable\n","name: bert.encoder.layer.9.attention.self.query.bias is trainable\n","name: bert.encoder.layer.9.attention.self.key.weight is trainable\n","name: bert.encoder.layer.9.attention.self.key.bias is trainable\n","name: bert.encoder.layer.9.attention.self.value.weight is trainable\n","name: bert.encoder.layer.9.attention.self.value.bias is trainable\n","name: bert.encoder.layer.9.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.9.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.9.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.9.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.9.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.9.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.9.output.dense.weight is trainable\n","name: bert.encoder.layer.9.output.dense.bias is trainable\n","name: bert.encoder.layer.9.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.9.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.10.attention.self.query.weight is trainable\n","name: bert.encoder.layer.10.attention.self.query.bias is trainable\n","name: bert.encoder.layer.10.attention.self.key.weight is trainable\n","name: bert.encoder.layer.10.attention.self.key.bias is trainable\n","name: bert.encoder.layer.10.attention.self.value.weight is trainable\n","name: bert.encoder.layer.10.attention.self.value.bias is trainable\n","name: bert.encoder.layer.10.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.10.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.10.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.10.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.10.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.10.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.10.output.dense.weight is trainable\n","name: bert.encoder.layer.10.output.dense.bias is trainable\n","name: bert.encoder.layer.10.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.10.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.11.attention.self.query.weight is trainable\n","name: bert.encoder.layer.11.attention.self.query.bias is trainable\n","name: bert.encoder.layer.11.attention.self.key.weight is trainable\n","name: bert.encoder.layer.11.attention.self.key.bias is trainable\n","name: bert.encoder.layer.11.attention.self.value.weight is trainable\n","name: bert.encoder.layer.11.attention.self.value.bias is trainable\n","name: bert.encoder.layer.11.attention.output.dense.weight is trainable\n","name: bert.encoder.layer.11.attention.output.dense.bias is trainable\n","name: bert.encoder.layer.11.attention.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.11.attention.output.LayerNorm.bias is trainable\n","name: bert.encoder.layer.11.intermediate.dense.weight is trainable\n","name: bert.encoder.layer.11.intermediate.dense.bias is trainable\n","name: bert.encoder.layer.11.output.dense.weight is trainable\n","name: bert.encoder.layer.11.output.dense.bias is trainable\n","name: bert.encoder.layer.11.output.LayerNorm.weight is trainable\n","name: bert.encoder.layer.11.output.LayerNorm.bias is trainable\n","name: bert.pooler.dense.weight is trainable\n","name: bert.pooler.dense.bias is trainable\n","name: l0.weight is trainable\n","name: l0.bias is trainable\n"]}],"source":["bert = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\n","tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# bert = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\n","model = BERTBengaliLastTwoPooler(bert)\n","# model2Forlastlayers = CustomBERTBengali(bert)\n","\n","model.to(device)\n","# model2Forlastlayers.to(device)\n","# model2Forlastlayers.load_state_dict(torch.load(DirPath+'Models by Sami/'+bert_model_name+\"_modeltest.pth\"))\n","\n","# model.l0 = model2Forlastlayers.l0\n","# model.l2 = model2Forlastlayers.l1\n","# model.bert = model2Forlastlayers.bert\n","\n","# model.load_state_dict(torch.load(DirPath+bert_model_name+\"_lasttwopoolerf_contest_val_from_HScollected_lastfrozen_acc1_sub.pth\"))\n","\n","# for params in model.bert.parameters():\n","#   params.requires_grad = False\n","# for params in model.bert.embeddings.parameters():\n","#   params.requires_grad = True\n","# for params in model.bert.encoder.parameters():\n","#   params.requires_grad = False\n","# # for params in model.l2.parameters():\n","# #   params.requires_grad = True\n","# # for params in model.l1.parameters():\n","# #   params.requires_grad = True\n","# for params in model.l0.parameters():\n","#   params.requires_grad = True\n","\n","for name, param in model.named_parameters():\n","  if param.requires_grad:\n","      print(f\"name: {name} is trainable\")\n","  else:\n","      print(f\"name: {name} is non-trainable\")"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3099,"status":"ok","timestamp":1697644031788,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"OmRT5yjsvdDK","outputId":"5d429b9f-7a0a-4436-a342-551556e8caf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': tensor([[  101,   608, 36873, 48094, 12067,   620, 19801,   620, 43197,   591,\n","           102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n","tensor([[-0.2532, -0.3132]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]}],"source":["#testing if the input of model works before starting training\n","s = \"আমি বাংলায় গান গাই। [SEP]\"\n","\n","# debugging dataloader\n","# i = 0\n","# for batch in train_dataloader:\n","#   text, labels = batch\n","#   for j in range(len(text)):\n","#     print(i+1)\n","#     i+=1\n","\n","# s=headlineContentSeparator\n","# print(s)\n","t = tokenizer.encode_plus(s, return_tensors=\"pt\").to(device)\n","print(t)\n","out = model(**t)\n","print(out)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1697644031788,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"fUJOHWMgm3fw","outputId":"7ba587ee-d3e7-45e5-875b-b213f4e69707"},"outputs":[{"output_type":"stream","name":"stdout","text":["গ্যাসের দাম বাড়ানোর সিদ্ধান্ত থেকে সরেছে সরকার হাসান মাহামুদ : শিল্পকারখানা, বাণিজ্যিক প্রতিষ্ঠান ও যানবাহনের জন্য গ্যাসের দাম বাড়ানোর ঘোষণা আসার কথা ছিল চলতি সপ্তাহেই। সরকারের সংশ্লিষ্ট সংস্থাগুলোর পক্ষ থেকে গ্যাসের দাম বৃদ্ধির পরিষ্কার আভাসও ছিল। কিন্তু জাতীয় সংসদ নির্বাচনকে সামনে রেখে এ সিদ্ধান্ত থেকে সরে এসেছে সরকার। বাংলাদেশ এনার্জি রেগুলেটরি কমিশনের (বিইআরসি) একটি বিশ্বস্ত সূত্র জানিয়েছে, নির্বাচনকে সামনে রেখে গ্যাসের মূল্য বৃদ্ধির ব্যাপারে অনেক কিছু ভেবে দেখেছে কমিশন। আপাতত গ্যাসের দাম বাড়ানোর সিদ্ধান্ত কার্যকর করছে না সরকার। জানা গেছে, এর আগে উচ্চমূল্যে তরলীকৃত প্রাকৃতিক গ্যাস (এলএনজি) আমদানির ওপর সম্পূরক শুল্ক (এসডি) মওকুফের জন্য সরকারের সিদ্ধান্তের অপেক্ষায় থাকা বিইআরসি সম্পূরক শুল্ক ব্যয় মেটাতেই গ্যাসের মূল্য বৃদ্ধির পরিকল্পনা করে। কিন্তু প্রধানমন্ত্রী শেখ হাসিনার নির্দেশে জ্বালানি সংক্রান্ত সর্বোচ্চ নীতিনির্ধারণী সংস্থা গ্যাসের মূল্য বৃদ্ধির বিষয়টি আপাতত স্থগিত রেখেছে। জানা গেছে, সম্পূরক শুল্ক মওকুফের পর গ্যাসের মূল্যের সাথে রেগুলেটরি কমিশন এখন সমন্বয়ের কাজ করছে। ফলে গ্যাসের মূল্য বৃদ্ধির সিদ্ধান্তের জন্য আরো কিছু সময় লাগবে। সেক্ষেত্রে চলতি বছরে এই সিদ্ধান্ত আসার সম্ভাবনা কম বলে জানা গেছে। এ বিষয়ে রেগুলেটরি কমিশনের সদস্য মিজানুর রহমান বলেন, ‘এ বিষয়ে সুনির্দিষ্টভাবে এখনই কিছু বলা যাচ্ছে না। তবে সিদ্ধান্তের জন্য আরো কিছু সময় অপেক্ষা করতে হবে।’ খাত সংশ্লিষ্টরা বলছেন, গ্যাসের দাম বৃদ্ধি খুবই স্পর্শকাতর বিষয়। কারণ, গ্যাসের মূল্যের সাথে আরো অনেক খাত জড়িয়ে থাকে। গ্যাসের মূল্যের ওপর যেকোনো সিদ্ধান্তই অর্থনীতির ওপর বড় ধরনের প্রভাব ফেলে। আগামী নির্বাচনের আগে সেটা সরকার কখনোই চাইবে না। গত জুনে এলএনজি আমদানি চূড়ান্ত হওয়ার পরই গ্যাসের দাম বাড়ানোর তোড়জোড় শুরু হয়। জুনের ১১ তারিখ থেকে দাম বাড়ানোর ওপর শুনানি করে রেগুলেটরি কমিশন। শুনানিতে প্রতি ঘনমিটার গ্যাসের গড় দাম ৭ টাকা ৩৯ পয়সা থেকে বাড়িয়ে ১২ টাকা ৯৫ পয়সা করার প্রস্তাব করেছে কোম্পানিগুলো। কোম্পানিগুলোর মধ্যে রয়েছে- তিতাস গ্যাস ট্রান্স ট্রান্সমিশন অ্যান্ড ডিস্ট্রিবিউশন কোম্পানি লিমিটেড, বাখরাবাদ গ্যাস ডিস্ট্রিবিউশন কোম্পানি লিমিটেড, জালালাবাদ গ্যাস ট্রান্সমিশন অ্যান্ড ডিস্ট্রিবিউশন সিস্টেম লিমিটেড, পশ্চিমাঞ্চল গ্যাস কোম্পানি লিমিটেড, কর্ণফুলী গ্যাস ডিস্ট্রিবিউশন কোম্পানি লিমিটেড ও সুন্দরবন গ্যাস কোম্পানি লিমিটেড। আবেদনে সব মিলিয়ে ৭৩ শতাংশ দাম বাড়ানোর প্রস্তাব করা হয়। শুনানিতে পেট্রোবাংলার পক্ষ থেকে বিইআরসিকে বলা হয়- ভ্যাট, ব্যাংক চার্জ, রিগ্যাসিফিকেশন চার্জসহ নানা ধরনের চার্জ যোগ করে আমদানি করা এলএনজির বিক্রয়মূল্য দাঁড়াবে ৩৩ টাকা ৪৪ পয়সা, যা বর্তমানে বিক্রিত গ্যাসের চার গুণ বেশি। শুনানির সময় গ্যাস খাতের প্রতিষ্ঠানগুলো যুক্তি দেখায়, উচ্চমূল্যে আমদানিকৃত এলএনজি ব্যয়ের কারণে সরকারের সিদ্ধান্ত অনুযায়ী সংশ্লিষ্ট ক্ষেত্রে দাম বাড়ানোর প্রস্তাব জমা দিতে হয় তাদের। কারণ, এতে তাদের খরচ যথেষ্ট পরিমাণে বেড়ে যাবে। আর উচ্চমূল্যের প্রভাব পড়বে বিদ্যুৎকেন্দ্র, সার কারখানা, সিএনজি স্টেশন, শিল্পকারখানা ও ক্যাপটিভ বিদ্যুৎকেন্দ্রগুলোর ওপর। শুনানি শেষ হওয়ার ৯০ কার্যদিবসের মধ্যে দাম বাড়ানোর ঘোষণা দেওয়ার কথা। কিন্তু এই ঘোষণা কবে নাগাদ আসে, সে বিষয়ে কমিশনের কর্মকর্তারা জানাতে পারেননি। এ বিষয়ে কমিশনের ট্যারিফ শাখার এক কর্মকর্তার কাছে জানতে চাইলে তিনি রাইজিংবিডিকে বলেন, ‘বিষয়টি খুবই স্পর্শকাতর। এখনই এ বিষয়ে কিছু জানানো যাচ্ছে না। তবে এই সপ্তাহে কোনো রকম সিদ্ধান্ত আসবে না, এটি আশ্বস্ত করা যাচ্ছে।’ রাইজিংবিডি/ঢাকা/৯ অক্টোবর ২০১৮/হাসান/রফিক\n"]}],"source":["print(df_train.iloc[94]['Headline'],df_train.iloc[94]['Content'])"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697644031788,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"ZaJ8Ro_CxcPQ"},"outputs":[],"source":["from torch.optim.lr_scheduler import StepLR\n","\n","optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=adam_opt_lr)\n","criterion = nn.CrossEntropyLoss()\n","scheduler = StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697644031788,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"Q-YKSmNf1HrB"},"outputs":[],"source":["def train(model, dataloader, optimizer, criterion, config):\n","    model.train()  # prep model for training\n","    train_loss = 0\n","    for batch in tqdm(dataloader):\n","        text, labels = batch\n","\n","        model.zero_grad()\n","\n","        inputs = tokenizer.batch_encode_plus(\n","            text, **config\n","        )\n","        input_ids = inputs['input_ids'].to(device)\n","        token_type_ids = inputs['token_type_ids'].to(device)\n","        attention_mask = inputs['attention_mask'].to(device)\n","        #labels = labels.to(device)\n","        labels = labels.to(device, dtype=torch.long)  # Convert labels to torch.long\n","\n","        # move things to model\n","        logs = model( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","\n","        loss = criterion(logs, labels)\n","        #print(\"successfully calculated criterion in train!\")\n","        train_loss += loss.item() * input_ids.size(0)\n","        loss.backward()\n","\n","        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","    return train_loss"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1697644031789,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"WULrKYWT1jyv"},"outputs":[],"source":["def evaluate(model, dataloader, criterion, config):\n","    total = 0\n","    correct = 0\n","    valid_loss = 0.0\n","    label_0_TP = 0\n","    label_0_TN = 0\n","    label_0_FP = 0\n","    label_0_FN = 0\n","\n","    label_1_TP = 0\n","    label_1_TN = 0\n","    label_1_FP = 0\n","    label_1_FN = 0\n","\n","    label_2_TP = 0\n","    label_2_TN = 0\n","    label_2_FP = 0\n","    label_2_FN = 0\n","\n","    model.eval()  # prep model for evaluation\n","    for batch in dataloader:\n","        text, labels = batch\n","        inputs = tokenizer.batch_encode_plus(\n","            text, **config\n","        )\n","        input_ids = inputs['input_ids'].to(device)\n","        token_type_ids = inputs['token_type_ids'].to(device)\n","        attention_mask = inputs['attention_mask'].to(device)\n","        labels = labels.to(device, dtype=torch.long)\n","\n","        # move things to model\n","        output = model(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n","\n","        loss_p = criterion(output, labels)\n","        # update running validation loss\n","        valid_loss += loss_p.item() * input_ids.size(0)\n","        # calculate accuracy\n","        proba = torch.exp(output)\n","        top_p, top_class = proba.topk(1, dim=1)\n","        equals = top_class == labels.view(*top_class.shape)\n","        # accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","\n","        _, predicted = torch.max(output.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","        #print(f'predicted: {predicted} labels: {labels}')\n","        label_0_TP += ((predicted == 0) & (labels == 0)).sum().item()\n","        label_0_TN += ((predicted != 0) & (labels != 0)).sum().item()\n","        label_0_FP += ((predicted == 0) & (labels != 0)).sum().item()\n","        label_0_FN += ((predicted != 0) & (labels == 0)).sum().item()\n","\n","        label_1_TP += ((predicted == 1) & (labels == 1)).sum().item()\n","        label_1_TN += ((predicted != 1) & (labels != 1)).sum().item()\n","        label_1_FP += ((predicted == 1) & (labels != 1)).sum().item()\n","        label_1_FN += ((predicted != 1) & (labels == 1)).sum().item()\n","\n","        label_2_TP += ((predicted == 2) & (labels == 2)).sum().item()\n","        label_2_TN += ((predicted != 2) & (labels != 2)).sum().item()\n","        label_2_FP += ((predicted == 2) & (labels != 2)).sum().item()\n","        label_2_FN += ((predicted != 2) & (labels == 2)).sum().item()\n","\n","    return total, correct, valid_loss, label_0_TP, label_0_TN, label_0_FP, label_0_FN, label_1_TP, label_1_TN, label_1_FP, label_1_FN, label_2_TP, label_2_TN, label_2_FP, label_2_FN\n"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697644031789,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"},"user_tz":-360},"id":"Jfz6yeuc1pUZ"},"outputs":[],"source":["\n","tokenizer_config = {\n","    \"max_length\": max_number_input_tokens,\n","    \"padding\": \"max_length\",\n","    \"return_tensors\": \"pt\",\n","    \"truncation\": True,\n","    \"add_special_tokens\": True,\n","     \"truncation_strategy\":\"longest_first\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":408,"referenced_widgets":["b41061d321534d54b82a20b13045bed7","13c077a601d445c0a59386c08034f606","0b51934ed6f74e05a3964ccd96d4ed60","53139b1822104a9e86ac162a4c6849bd","18c742cc92174c71a8e1814443a756e7","7668f495359544a094178275d5bb08df","362a3b25af7848a7bd0355aaf7d422fb","2f0cc2bae457428187a5dd8f89ea4b9f","4796ba9d3800448cbb3d625d9ffdc906","782be1b2a2a041afaf4dc11d31df8c87","e01b9e3f18f3410594afb078e6db4433","2e5530e7b14c4adaab1207fc12fd64ee","e3fa147e129c4b89abe51550fd64d2b9","346878912d4c4f3dbca2f6b9ccc0e4d5","8ff14d15d2104d81a7fae4d5f5aa6bdc","afb5d9f264364f0cbd44fb02e779987b","3f5e358f037740b69b885635fb1dea22","baf2b97dfb3d4b0d87ca56acf58f53bc","fdc1c31e59314ba8b2b54c14c6fa0026","5a5b5834719a4c7599d397004f45469f","17429152d20c4dd8b4f6b9724136a5f9","5274616b9f6a4c6e8fed62ec09d2ccb4","6cf69e0b090d46c292c239fc95c250e9","9d4800184be245cba1e38a318e199e75","a62aa3c544e641a0bf9217188642b867","24189a801ae74b68be8d885d44129f63","67288c1767b145f2965dfb4417553e93","8e10a3eaf6d34054961466ad2dd84117","0cd504b7238a4abf972192e3b8be502e","1bebfc1c9c9f4f41a8be0d90b320e4d2","2c0c090e9e0842a28f18f1000ae412aa","9883e8a83b2745f08d5f43e6acad2f39","6c040fd62f424d50b70e11e778715ac1"]},"id":"petGI7zd4LAm","outputId":"be80d6c7-73b6-4a24-bc58-ffe900c5dd96"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b41061d321534d54b82a20b13045bed7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5389 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["saved on epoch: 1\n","\tTrain loss:0.335398.. \tValid Loss:0.343582.. \tVal Accuracy: 92.0862\n","\tLabel 0 Precision: 0.9725\tLabel 0 Recall: 0.6403\tLabel 0 F1-score: 0.7722\n","\tLabel 1 Precision: 0.9126\tLabel 1 Recall: 0.9952\tLabel 1 F1-score: 0.9521\n","\tLabel 2 Precision: 0.0000\tLabel 2 Recall: 0.0000\tLabel 2 F1-score: 0.0000\n","\tCombined F1-score: 0.8622\n","micro precision: 0.920861751650969, Micro recall: 0.920861751650969, micro f1: 0.920861751650969\n","Epoch: 2/8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2e5530e7b14c4adaab1207fc12fd64ee","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5389 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["saved on epoch: 2\n","\tTrain loss:0.282334.. \tValid Loss:0.269092.. \tVal Accuracy: 92.7466\n","\tLabel 0 Precision: 0.9408\tLabel 0 Recall: 0.6977\tLabel 0 F1-score: 0.8012\n","\tLabel 1 Precision: 0.9250\tLabel 1 Recall: 0.9884\tLabel 1 F1-score: 0.9556\n","\tLabel 2 Precision: 0.0000\tLabel 2 Recall: 0.0000\tLabel 2 F1-score: 0.0000\n","\tCombined F1-score: 0.8784\n","micro precision: 0.9274656273681932, Micro recall: 0.9274656273681932, micro f1: 0.9274656273681932\n","Epoch: 3/8\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cf69e0b090d46c292c239fc95c250e9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5389 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_loss_data, valid_loss_data = [], []\n","valid_loss_min = np.Inf\n","since = time.time()\n","best_loss = np.inf\n","best_acc=0\n","sml = 1e-10\n","best_f1=0.0\n","\n","for epoch in range(epochs):\n","    print(\"Epoch: {}/{}\".format(epoch + 1, epochs))\n","    # monitor training loss\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    total = 0\n","    correct = 0\n","    label_0_TP = 0\n","    label_0_TN = 0\n","    label_0_FP = 0\n","    label_0_FN = 0\n","\n","    label_1_TP = 0\n","    label_1_TN = 0\n","    label_1_FP = 0\n","    label_1_FN = 0\n","\n","    label_2_TP = 0\n","    label_2_TN = 0\n","    label_2_FP = 0\n","    label_2_FN = 0\n","\n","\n","    e_since = time.time()\n","\n","    # Train Model\n","    train_loss += train(model, train_dataloader, optimizer, criterion, tokenizer_config)\n","    # Now Evaluate\n","    out = evaluate(model, val_dataloader, criterion, tokenizer_config)\n","    total += out[0]\n","    correct += out[1]\n","    valid_loss += out[2]\n","    label_0_TP += out[3]\n","    label_0_TN += out[4]\n","    label_0_FP += out[5]\n","    label_0_FN += out[6]\n","\n","    label_1_TP += out[7]\n","    label_1_TN += out[8]\n","    label_1_FP += out[9]\n","    label_1_FN += out[10]\n","\n","    # label_2_TP += out[11]\n","    # label_2_TN += out[12]\n","    # label_2_FP += out[13]\n","    # label_2_FN += out[14]\n","\n","    # Calculate precision, recall, and F1-score for each class\n","    label_0_precision = label_0_TP / (label_0_TP + label_0_FP+sml)\n","    label_0_recall = label_0_TP / (label_0_TP + label_0_FN+sml)\n","    label_0_f1_score = 2 * (label_0_precision * label_0_recall) / (label_0_precision + label_0_recall+sml)\n","\n","    label_1_precision = label_1_TP / (label_1_TP + label_1_FP+sml)\n","    label_1_recall = label_1_TP / (label_1_TP + label_1_FN+sml)\n","    label_1_f1_score = 2 * (label_1_precision * label_1_recall) / (label_1_precision + label_1_recall+sml)\n","\n","    label_2_precision = label_2_TP / (label_2_TP + label_2_FP+sml)\n","    label_2_recall = label_2_TP / (label_2_TP + label_2_FN+sml)\n","    label_2_f1_score = 2 * (label_2_precision * label_2_recall) / (label_2_precision + label_2_recall+sml)\n","\n","    # Calculate combined F1-score\n","    combined_f1_score = (label_0_f1_score + label_1_f1_score) / 2\n","\n","    # Calculate micro TP, TN, FP, FN values\n","    micro_TP = label_0_TP + label_1_TP\n","    micro_TN = label_0_TN + label_1_TN\n","    micro_FP = label_0_FP + label_1_FP\n","    micro_FN = label_0_FN + label_1_FN\n","\n","    # Calculate micro precision, recall, and F1 score\n","    micro_precision = micro_TP / (micro_TP + micro_FP)\n","    micro_recall = micro_TP / (micro_TP + micro_FN)\n","    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall)\n","\n","    scheduler.step()\n","\n","    # print training/validation statistics\n","    # calculate average loss over an epoch\n","    train_loss = train_loss / len(train_dataloader.dataset)\n","    valid_loss = valid_loss / len(val_dataloader.dataset)\n","\n","    val_acc=correct / total * 100\n","\n","    # calculate train loss and running loss\n","    train_loss_data.append(train_loss * 100)\n","    valid_loss_data.append(valid_loss * 100)\n","\n","    if combined_f1_score > best_f1:\n","        best_f1 = combined_f1_score\n","        torch.save(model.state_dict(), ModelPath)\n","        print(f'saved on epoch: {epoch+1}')\n","\n","    print(\"\\tTrain loss:{:.6f}..\".format(train_loss),\n","          \"\\tValid Loss:{:.6f}..\".format(valid_loss),\n","          \"\\tVal Accuracy: {:.4f}\".format(correct / total * 100))\n","    print(\"\\tLabel 0 Precision: {:.4f}\\tLabel 0 Recall: {:.4f}\\tLabel 0 F1-score: {:.4f}\\n\"\n","      \"\\tLabel 1 Precision: {:.4f}\\tLabel 1 Recall: {:.4f}\\tLabel 1 F1-score: {:.4f}\\n\"\n","      \"\\tLabel 2 Precision: {:.4f}\\tLabel 2 Recall: {:.4f}\\tLabel 2 F1-score: {:.4f}\\n\"\n","      \"\\tCombined F1-score: {:.4f}\".format(label_0_precision, label_0_recall, label_0_f1_score,\n","                                            label_1_precision, label_1_recall, label_1_f1_score,\n","                                            label_2_precision, label_2_recall, label_2_f1_score,\n","                                            combined_f1_score))\n","    print(f'micro precision: {micro_precision}, Micro recall: {micro_recall}, micro f1: {micro_f1}')\n","\n","time_elapsed = time.time() - since\n","print('Training completed in {:.0f}m {:.0f}s'.format(\n","    time_elapsed // 60, time_elapsed % 60))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"muKYec9IECUQ"},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcnJ4S_u65BO"},"outputs":[],"source":["# torch.save(model.state_dict(), DirPath+bert_model_name+\"_lasttwopoolerf_contest_val_from_finalhs_midnonfrozen_acc1_sub_finaluntested.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYYhjA944Qgi"},"outputs":[],"source":["from matplotlib import pyplot as plt\n","\n","plt.plot(train_loss_data, label=\"Training loss\")\n","plt.plot(valid_loss_data, label=\"validation loss\")\n","plt.legend(frameon=False)"]},{"cell_type":"markdown","metadata":{"id":"lfWfx3Zi4COD"},"source":["# Testing on test dataset"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"-d8iU2p64rrh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697644052519,"user_tz":-360,"elapsed":12924,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"}},"outputId":"073ab172-886a-46c3-dc58-aa0460559d20"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":24}],"source":["model.load_state_dict(torch.load(ModelPath))"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"VD8JGmErGJEw","executionInfo":{"status":"ok","timestamp":1697644359117,"user_tz":-360,"elapsed":306612,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"}}},"outputs":[],"source":["all_preds = []\n","all_labels = []\n","\n","\n","df_test = pd.read_csv(TestPath)\n","test_data = NewsDatasets(df_test)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size_training, shuffle=False)\n","\n","for batch in test_dataloader:\n","    text, labels = batch\n","    inputs = tokenizer.batch_encode_plus(\n","        text, **tokenizer_config\n","    )\n","    input_ids = inputs['input_ids'].to(device)\n","    token_type_ids = inputs['token_type_ids'].to(device)\n","    attention_mask = inputs['attention_mask'].to(device)\n","    labels = labels.to(device)\n","\n","    # move things to model\n","    output = model(token_type_ids=token_type_ids, input_ids=input_ids, attention_mask=attention_mask)\n","    preds = output.detach().cpu().numpy()\n","    preds = np.argmax(preds, axis = 1)\n","    all_preds.extend(preds)\n","    all_labels.extend(labels.cpu().numpy())\n","\n","# df_test['real_HS'] = all_labels\n","# df_test['predicted_HS'] = all_preds\n","# df_test.to_csv(DirPath+'nc/'+'test_HS_pred.csv')"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"WjkUCAtGe5mm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697644359118,"user_tz":-360,"elapsed":18,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"}},"outputId":"cea5f934-8fbe-4bf7-df78-b8beff0d6139"},"outputs":[{"output_type":"stream","name":"stdout","text":["9238\n"]}],"source":["print(len(all_preds))"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"m7UdyABYGRdb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697644360005,"user_tz":-360,"elapsed":902,"user":{"displayName":"Shrestha Datta9","userId":"08271096333592359426"}},"outputId":"c11c97d1-975f-41d1-ff23-c4ebd3663c3f"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0     0.9314    0.7009    0.7999      1936\n","           1     0.9256    0.9863    0.9550      7302\n","\n","    accuracy                         0.9265      9238\n","   macro avg     0.9285    0.8436    0.8774      9238\n","weighted avg     0.9268    0.9265    0.9225      9238\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","# preds = np.argmax(preds, axis = 1)\n","print(classification_report(all_labels, all_preds, digits=4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMPUT4Qn8DZr"},"outputs":[],"source":["all_preds = []\n","all_labels = []\n","\n","\n","df_test = pd.read_csv(DirPath+'Dataset/final_test.xlsx - test.csv')\n","training_data = NewsDatasets(df_test)\n","train_dataloader = DataLoader(training_data, batch_size=batch_size_training, shuffle=True)\n","\n","for batch in train_dataloader:\n","    text, labels = batch\n","    inputs = tokenizer.batch_encode_plus(\n","        text, **tokenizer_config\n","    )\n","    input_ids = inputs['input_ids'].to(device)\n","    token_type_ids = inputs['token_type_ids'].to(device)\n","    attention_mask = inputs['attention_mask'].to(device)\n","    labels = labels.to(device)\n","\n","    # move things to model\n","    output = model(token_type_ids=token_type_ids, input_ids=input_ids, attention_mask=attention_mask)\n","    preds = output.detach().cpu().numpy()\n","    preds = np.argmax(preds, axis = 1)\n","    all_preds.extend(preds)\n","    all_labels.extend(labels.cpu().numpy())\n","\n","df_test['real_HS'] = all_labels\n","df_test['predicted_HS'] = all_preds\n","df_test.to_csv(DirPath+'nc/'+'val_HS_pred.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdVN3-7zFx3l"},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","# preds = np.argmax(preds, axis = 1)\n","print(classification_report(all_labels, all_preds))"]},{"cell_type":"markdown","metadata":{"id":"gZrljC9YjCNQ"},"source":["<h1>Training the model with All Collected dataset with the selected model and hyperparameters(Code not yet updated)<h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0qev8l4jq6O"},"outputs":[],"source":["!pip install --quiet transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ThJXgxvj3gH"},"outputs":[],"source":["import time\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","from tqdm.notebook import tqdm\n","from transformers import BertModel, BertTokenizer, BertForSequenceClassification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-xdZUKdxkCPv"},"outputs":[],"source":["#df loading\n","df_train = pd.read_csv('train.csv')[['sentence','hate speech']]\n","df_val = pd.read_csv('val.csv')[['sentence','hate speech']]\n","df_test = pd.read_csv('test.csv')[['sentence','hate speech']]\n","\n","#concatenating all the data\n","df_train = pd.concat([df_train, df_val, df_test], ignore_index=True)\n","\n","print(df_train.shape)\n","print(df_val.shape)\n","print(df_test.shape)\n","print(df_train)\n","print(df_train.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AV03rC3pk1QX"},"outputs":[],"source":["#defining previous hyperparameters got from testing\n","max_number_input_tokens=256\n","batch_size_training = 16\n","first_dropout_rate = 0.3\n","hidden_output = 768\n","bert_model_name = \"sagorsarker/bangla-bert-base\"\n","adam_opt_lr = 3e-5\n","scheduler_step = 1\n","scheduler_gamma = 0.8\n","epochs = 6\n","classes = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"miIj9oCklCtV"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","DirPath = ('/content/drive/My Drive/Test/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDDFZzD2lJhK"},"outputs":[],"source":["class NewsDatasets(Dataset):\n","    def __init__(self, data, max_length=max_number_input_tokens):\n","        self.data = data\n","\n","        self.config = {\n","            \"max_length\": max_length,\n","            \"padding\": \"max_length\",\n","            \"return_tensors\": \"pt\",\n","            \"truncation\": True,\n","            \"add_special_tokens\": True,\n","            \"truncation_strategy\":\"longest_first\"\n","        }\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        value = self.data.iloc[idx]\n","        return value['sentence'] , value['hate speech']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GX135RhClpa7"},"outputs":[],"source":["training_data = NewsDatasets(df_train)\n","train_dataloader = DataLoader(training_data, batch_size=batch_size_training, shuffle=True)\n","\n","val_data = NewsDatasets(df_val)\n","val_dataloader = DataLoader(val_data, batch_size=batch_size_training, shuffle=True)\n","\n","test_data = NewsDatasets(df_test)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size_training, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f6UhqDxyl0ch"},"outputs":[],"source":["class CustomBERTBengali(nn.Module):\n","    def __init__(self, bert):\n","        super(CustomBERTBengali, self).__init__()\n","        self.bert = bert\n","        self.bert_drop = nn.Dropout(first_dropout_rate)\n","        self.tanh = nn.Tanh()\n","        self.out = nn.Linear(hidden_output * 3, classes)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_ids, attention_mask, token_type_ids):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids\n","        )\n","        o1 = outputs.hidden_states[-1]\n","        o2 = outputs.pooler_output\n","        apool = torch.mean(o1, 1)\n","        mpool, _ = torch.max(o1, 1)\n","        pooled_output = o2\n","        cat = torch.cat((apool, mpool, pooled_output), 1)\n","        bo = self.bert_drop(cat)\n","        logits = self.out(bo)\n","        logits = self.softmax(logits)\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iSQ7Ub4l60H"},"outputs":[],"source":["bert = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\n","tokenizer = BertTokenizer.from_pretrained(bert_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rDznOw8Ol8mV"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = CustomBERTBengali(bert)\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R2Nyc8fTmXl3"},"outputs":[],"source":["from torch.optim.lr_scheduler import StepLR\n","\n","optimizer = AdamW(model.parameters(), lr=adam_opt_lr)\n","criterion = nn.CrossEntropyLoss()\n","scheduler = StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ufV3a1Z8mdGH"},"outputs":[],"source":["def train(model, dataloader, optimizer, criterion, config):\n","    model.train()  # prep model for training\n","    train_loss = 0\n","    for batch in tqdm(dataloader):\n","        text, labels = batch\n","\n","        model.zero_grad()\n","\n","        inputs = tokenizer.batch_encode_plus(\n","            text, **config\n","        )\n","        input_ids = inputs['input_ids'].to(device)\n","        token_type_ids = inputs['token_type_ids'].to(device)\n","        attention_mask = inputs['attention_mask'].to(device)\n","        #labels = labels.to(device)\n","        labels = labels.to(device, dtype=torch.long)  # Convert labels to torch.long\n","\n","        # move things to model\n","        logs = model(token_type_ids=token_type_ids, input_ids=input_ids, attention_mask=attention_mask)\n","\n","        loss = criterion(logs, labels)\n","        train_loss += loss.item() * input_ids.size(0)\n","        loss.backward()\n","\n","        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","    return train_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iw0YDvjkmnHw"},"outputs":[],"source":["def evaluate(model, dataloader, criterion, config):\n","    total = 0\n","    correct = 0\n","    valid_loss = 0.0\n","\n","    model.eval()  # prep model for evaluation\n","    for batch in dataloader:\n","        text, labels = batch\n","        inputs = tokenizer.batch_encode_plus(\n","            text, **config\n","        )\n","        input_ids = inputs['input_ids'].to(device)\n","        token_type_ids = inputs['token_type_ids'].to(device)\n","        attention_mask = inputs['attention_mask'].to(device)\n","        labels = labels.to(device)\n","\n","        # move things to model\n","        output = model(token_type_ids=token_type_ids, input_ids=input_ids, attention_mask=attention_mask)\n","\n","        loss_p = criterion(output, labels)\n","        # update running validation loss\n","        valid_loss += loss_p.item() * input_ids.size(0)\n","        # calculate accuracy\n","        proba = torch.exp(output)\n","        top_p, top_class = proba.topk(1, dim=1)\n","        equals = top_class == labels.view(*top_class.shape)\n","        # accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n","\n","        _, predicted = torch.max(output.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","    return total, correct, valid_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foLVh7k6msA3"},"outputs":[],"source":["tokenizer_config = {\n","    \"max_length\": max_number_input_tokens,\n","    \"padding\": \"max_length\",\n","    \"return_tensors\": \"pt\",\n","    \"truncation\": True,\n","    \"add_special_tokens\": True,\n","     \"truncation_strategy\":\"longest_first\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IcfncSwknBFV"},"outputs":[],"source":["train_loss_data, valid_loss_data = [], []\n","valid_loss_min = np.Inf\n","since = time.time()\n","best_loss = np.inf\n","\n","for epoch in range(epochs):\n","    print(\"Epoch: {}/{}\".format(epoch + 1, epochs))\n","    # monitor training loss\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    total = 0\n","    correct = 0\n","    e_since = time.time()\n","\n","    # Train Model\n","    train_loss += train(model, train_dataloader, optimizer, criterion, tokenizer_config)\n","    # Now Evaluate\n","    out = evaluate(model, val_dataloader, criterion, tokenizer_config)\n","    total += out[0]\n","    correct += out[1]\n","    valid_loss += out[2]\n","\n","    scheduler.step()\n","\n","    # print training/validation statistics\n","    # calculate average loss over an epoch\n","    train_loss = train_loss / len(train_dataloader.dataset)\n","    valid_loss = valid_loss / len(val_dataloader.dataset)\n","\n","    # calculate train loss and running loss\n","    train_loss_data.append(train_loss * 100)\n","    valid_loss_data.append(valid_loss * 100)\n","\n","    if True:\n","        best_loss = valid_loss\n","        torch.save(model.state_dict(), DirPath+bert_model_name+\"_CustomBertBengaliFullDataset6epoch885044valacc.pth\")\n","        print(f'epoch: {epoch+1}')\n","\n","    print(\"\\tTrain loss:{:.6f}..\".format(train_loss),\n","          \"\\tValid Loss:{:.6f}..\".format(valid_loss),\n","          \"\\tVal Accuracy: {:.4f}\".format(correct / total * 100))\n","\n","time_elapsed = time.time() - since\n","print('Training completed in {:.0f}m {:.0f}s'.format(\n","    time_elapsed // 60, time_elapsed % 60))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDrNVhFXor-F"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b51934ed6f74e05a3964ccd96d4ed60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f0cc2bae457428187a5dd8f89ea4b9f","max":5389,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4796ba9d3800448cbb3d625d9ffdc906","value":5389}},"0cd504b7238a4abf972192e3b8be502e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13c077a601d445c0a59386c08034f606":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7668f495359544a094178275d5bb08df","placeholder":"​","style":"IPY_MODEL_362a3b25af7848a7bd0355aaf7d422fb","value":"100%"}},"17429152d20c4dd8b4f6b9724136a5f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18c742cc92174c71a8e1814443a756e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bebfc1c9c9f4f41a8be0d90b320e4d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24189a801ae74b68be8d885d44129f63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9883e8a83b2745f08d5f43e6acad2f39","placeholder":"​","style":"IPY_MODEL_6c040fd62f424d50b70e11e778715ac1","value":" 4/5389 [00:03&lt;1:15:17,  1.19it/s]"}},"2c0c090e9e0842a28f18f1000ae412aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e5530e7b14c4adaab1207fc12fd64ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3fa147e129c4b89abe51550fd64d2b9","IPY_MODEL_346878912d4c4f3dbca2f6b9ccc0e4d5","IPY_MODEL_8ff14d15d2104d81a7fae4d5f5aa6bdc"],"layout":"IPY_MODEL_afb5d9f264364f0cbd44fb02e779987b"}},"2f0cc2bae457428187a5dd8f89ea4b9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"346878912d4c4f3dbca2f6b9ccc0e4d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdc1c31e59314ba8b2b54c14c6fa0026","max":5389,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a5b5834719a4c7599d397004f45469f","value":5389}},"362a3b25af7848a7bd0355aaf7d422fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f5e358f037740b69b885635fb1dea22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4796ba9d3800448cbb3d625d9ffdc906":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5274616b9f6a4c6e8fed62ec09d2ccb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53139b1822104a9e86ac162a4c6849bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_782be1b2a2a041afaf4dc11d31df8c87","placeholder":"​","style":"IPY_MODEL_e01b9e3f18f3410594afb078e6db4433","value":" 5389/5389 [1:15:20&lt;00:00,  1.49it/s]"}},"5a5b5834719a4c7599d397004f45469f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67288c1767b145f2965dfb4417553e93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c040fd62f424d50b70e11e778715ac1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cf69e0b090d46c292c239fc95c250e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d4800184be245cba1e38a318e199e75","IPY_MODEL_a62aa3c544e641a0bf9217188642b867","IPY_MODEL_24189a801ae74b68be8d885d44129f63"],"layout":"IPY_MODEL_67288c1767b145f2965dfb4417553e93"}},"7668f495359544a094178275d5bb08df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"782be1b2a2a041afaf4dc11d31df8c87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e10a3eaf6d34054961466ad2dd84117":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ff14d15d2104d81a7fae4d5f5aa6bdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17429152d20c4dd8b4f6b9724136a5f9","placeholder":"​","style":"IPY_MODEL_5274616b9f6a4c6e8fed62ec09d2ccb4","value":" 5389/5389 [1:15:43&lt;00:00,  1.49it/s]"}},"9883e8a83b2745f08d5f43e6acad2f39":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d4800184be245cba1e38a318e199e75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e10a3eaf6d34054961466ad2dd84117","placeholder":"​","style":"IPY_MODEL_0cd504b7238a4abf972192e3b8be502e","value":"  0%"}},"a62aa3c544e641a0bf9217188642b867":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bebfc1c9c9f4f41a8be0d90b320e4d2","max":5389,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2c0c090e9e0842a28f18f1000ae412aa","value":4}},"afb5d9f264364f0cbd44fb02e779987b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b41061d321534d54b82a20b13045bed7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13c077a601d445c0a59386c08034f606","IPY_MODEL_0b51934ed6f74e05a3964ccd96d4ed60","IPY_MODEL_53139b1822104a9e86ac162a4c6849bd"],"layout":"IPY_MODEL_18c742cc92174c71a8e1814443a756e7"}},"baf2b97dfb3d4b0d87ca56acf58f53bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e01b9e3f18f3410594afb078e6db4433":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3fa147e129c4b89abe51550fd64d2b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f5e358f037740b69b885635fb1dea22","placeholder":"​","style":"IPY_MODEL_baf2b97dfb3d4b0d87ca56acf58f53bc","value":"100%"}},"fdc1c31e59314ba8b2b54c14c6fa0026":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7aacc5450aaf43d59469f2b45fa80fe5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0d230aa88603405582e4637c97cf68b3","IPY_MODEL_a7a2300ad1a847a6a52e8c2c87a3e708","IPY_MODEL_d01a5d3d7c024e3e9230808cddcddca4"],"layout":"IPY_MODEL_3e5637ebf22a4597ad5491f089b0e7c4"}},"0d230aa88603405582e4637c97cf68b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4164cafdc0d847b7aa83967087892987","placeholder":"​","style":"IPY_MODEL_9b0ccec5b9c542878a610a38ebdf3c3a","value":"Downloading (…)lve/main/config.json: 100%"}},"a7a2300ad1a847a6a52e8c2c87a3e708":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03b38a5916324b61b9db9935047a0593","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57befa01df3a4d2f95ab030ed3b7fca8","value":625}},"d01a5d3d7c024e3e9230808cddcddca4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0fe7504b9ed4e6fa19237e4e96b7191","placeholder":"​","style":"IPY_MODEL_d593a8fe63214b9692fef55e91a6f50c","value":" 625/625 [00:00&lt;00:00, 38.6kB/s]"}},"3e5637ebf22a4597ad5491f089b0e7c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4164cafdc0d847b7aa83967087892987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b0ccec5b9c542878a610a38ebdf3c3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03b38a5916324b61b9db9935047a0593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57befa01df3a4d2f95ab030ed3b7fca8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0fe7504b9ed4e6fa19237e4e96b7191":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d593a8fe63214b9692fef55e91a6f50c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c75a7f464d3c46be9d179437e18532f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6dc29757dde4b92aafe09dac81c3595","IPY_MODEL_b5c2ae66786c47da8f99fd6f4500ae7c","IPY_MODEL_f2618c5944004f61bb7c5326e349a4a4"],"layout":"IPY_MODEL_3d7c646616594143a7873e366cd05774"}},"f6dc29757dde4b92aafe09dac81c3595":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67aad554bb284250b042774279e08b53","placeholder":"​","style":"IPY_MODEL_db2aaf67a8a94fcf8ccecac12026ab09","value":"Downloading model.safetensors: 100%"}},"b5c2ae66786c47da8f99fd6f4500ae7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62a1ca95ea6a4966ae40e5e74ef8b1ab","max":672247920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2342b7fb7eb421584f43cad5c8821a9","value":672247920}},"f2618c5944004f61bb7c5326e349a4a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd6bea4b34c94cc194d2de4c351310fb","placeholder":"​","style":"IPY_MODEL_ba24111f6d314235910d34123aba8857","value":" 672M/672M [00:02&lt;00:00, 305MB/s]"}},"3d7c646616594143a7873e366cd05774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67aad554bb284250b042774279e08b53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db2aaf67a8a94fcf8ccecac12026ab09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62a1ca95ea6a4966ae40e5e74ef8b1ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2342b7fb7eb421584f43cad5c8821a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd6bea4b34c94cc194d2de4c351310fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba24111f6d314235910d34123aba8857":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43eff258fb444bcda2962855d995fbf4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb2e571f31a445b99296fe3f2c710bde","IPY_MODEL_736c264482694094b62aef3ac4841b44","IPY_MODEL_52ddd3d40a474a51b8b3fd97b279462b"],"layout":"IPY_MODEL_f92d08e2a9164f32af1d4fd43610c623"}},"bb2e571f31a445b99296fe3f2c710bde":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_911a995098bf4f68bdd6d6ca15c1b1c6","placeholder":"​","style":"IPY_MODEL_569bb0d01e254aca914868043822c30c","value":"Downloading (…)okenizer_config.json: 100%"}},"736c264482694094b62aef3ac4841b44":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9519362ff4b489d95e0429a84090d24","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b12eae5c6b6241b1a3008a21d7f2dc5d","value":28}},"52ddd3d40a474a51b8b3fd97b279462b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae7e725858ad46ff98cd5406c7d0161b","placeholder":"​","style":"IPY_MODEL_5354b17935ce43b8a8876d2b3504a69e","value":" 28.0/28.0 [00:00&lt;00:00, 1.11kB/s]"}},"f92d08e2a9164f32af1d4fd43610c623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"911a995098bf4f68bdd6d6ca15c1b1c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"569bb0d01e254aca914868043822c30c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9519362ff4b489d95e0429a84090d24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b12eae5c6b6241b1a3008a21d7f2dc5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae7e725858ad46ff98cd5406c7d0161b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5354b17935ce43b8a8876d2b3504a69e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8230656aabcf4245a77bc5b4775841dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a61a834f7f5b4f9b9c2432bdae231860","IPY_MODEL_c3855fc4a51646acb462be38579419cf","IPY_MODEL_2b513541b41342108ae03a3c627388f0"],"layout":"IPY_MODEL_13642299507543bb89bb5e2078c366b0"}},"a61a834f7f5b4f9b9c2432bdae231860":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f42002b010a24db784789cd2bc62cfa7","placeholder":"​","style":"IPY_MODEL_64b7810ac2224898a78c50cf04c76d36","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"c3855fc4a51646acb462be38579419cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b81a2606ac3e47b0ae879f4480da601f","max":871891,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62e203044d2c4460a2cd93c0cae8d704","value":871891}},"2b513541b41342108ae03a3c627388f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_319c6a40daa74a98bd33030cb199792d","placeholder":"​","style":"IPY_MODEL_5bc8b324489d41b3b3bb93179c2e17ef","value":" 872k/872k [00:00&lt;00:00, 3.71MB/s]"}},"13642299507543bb89bb5e2078c366b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f42002b010a24db784789cd2bc62cfa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64b7810ac2224898a78c50cf04c76d36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b81a2606ac3e47b0ae879f4480da601f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62e203044d2c4460a2cd93c0cae8d704":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"319c6a40daa74a98bd33030cb199792d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bc8b324489d41b3b3bb93179c2e17ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db267d2070804805b2f090ded73f7198":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4fce8ab737a4f2ca13a68852c76a438","IPY_MODEL_ef412e451d524ebd85df4ec63668a57d","IPY_MODEL_2f07b0fae0614619815e089fe375621d"],"layout":"IPY_MODEL_30f300aa16ed441984aa81a478234e02"}},"f4fce8ab737a4f2ca13a68852c76a438":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33fb3d91c292412781a4aaaa4bfa063b","placeholder":"​","style":"IPY_MODEL_eef00cd64eb14d9c898b6167619f79dd","value":"Downloading (…)/main/tokenizer.json: 100%"}},"ef412e451d524ebd85df4ec63668a57d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eedb1062cc9e4b418c6e4330154a8870","max":1715180,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a1b74280444d4ac88159b3a703292d20","value":1715180}},"2f07b0fae0614619815e089fe375621d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da2c68f1b27b40fba070b246f42083e3","placeholder":"​","style":"IPY_MODEL_ebeb6a3138ca476f9974e66a3d0fd534","value":" 1.72M/1.72M [00:00&lt;00:00, 33.3MB/s]"}},"30f300aa16ed441984aa81a478234e02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33fb3d91c292412781a4aaaa4bfa063b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eef00cd64eb14d9c898b6167619f79dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eedb1062cc9e4b418c6e4330154a8870":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1b74280444d4ac88159b3a703292d20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da2c68f1b27b40fba070b246f42083e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebeb6a3138ca476f9974e66a3d0fd534":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}